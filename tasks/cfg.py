from __future__ import division

import random

import nltk.grammar as cfg
import torch
import torch.nn as nn
from nltk.parse.generate import generate
from torch.autograd import Variable

from base import Task


class CFGTask(Task):
    """

    """

    def __init__(self,
                 grammar,
                 to_predict,
                 sample_depth,
                 batch_size=10,
                 criterion=nn.CrossEntropyLoss(),
                 cuda=False,
                 epochs=100,
                 learning_rate=0.1,
                 max_length=25,
                 model=None,
                 null=u"#",
                 read_size=1,
                 verbose=True):
        """

        :param grammar:
        :param to_predict:
        :param sample_depth:
        :param batch_size:
        :param criterion:
        :param cuda:
        :param epochs:
        :param learning_rate:
        :param max_length:
        :param model:
        :param null:
        :param read_size:
        :param verbose:
        """
        super(CFGTask, self).__init__(max_x_length=max_length,
                                      max_y_length=max_length,
                                      learning_rate=learning_rate,
                                      batch_size=batch_size,
                                      read_size=read_size,
                                      cuda=cuda,
                                      epochs=epochs,
                                      model=model,
                                      criterion=criterion,
                                      verbose=verbose)

        self.grammar = grammar
        self.to_predict = to_predict
        self.sample_depth = sample_depth
        self.max_length = max_length
        self.null = null

        self.code_for = CFGTask.get_code_for(self.grammar, self.null)
        self.to_predict_code = self.words_to_code(*self.to_predict)
        self.sample_strings = self.generate_sample_strings()

    @staticmethod
    def get_code_for(grammar, null):
        """
        Creates an encoding of a CFG's terminal symbols as numbers.

        :type grammar: cfg.CFG
        :param grammar: A CFG

        :type null: unicode
        :param null: A string representing "null"

        :rtype: dict
        :return: A dict associating each terminal of the grammar with
            a unique number. The highest number represents "null."
        """
        rhss = [r.rhs() for r in grammar.productions()]
        rhs_symbols = set()
        rhs_symbols.update(*rhss)
        rhs_symbols = set(x for x in rhs_symbols if cfg.is_terminal(x))

        code_for = {x: i for i, x in enumerate(rhs_symbols)}
        code_for[null] = len(code_for)

        return code_for

    """ Model Training """

    def _evaluate_step(self, x, y, a, j):
        """


        :type x: torch.FloatTensor
        :param x: The input data, consisting of a set of
            strings of 0s and 1s

        :type y: Variable
        :param y: The output data, consisting of NULLs followed
            by the input strings backwards

        :type a: Variable
        :param a: The output of the neural network during this
            training step

        :type j: int
        :param j: The number of this trial

        :rtype: tuple
        :return:
        """
        _, y_pred = torch.max(a, 1)

        # Find the batch trials where we make a prediction
        null = self.code_for[self.null]
        valid_x = (y[:, j] != null).type(torch.FloatTensor)
        for k in xrange(len(valid_x)):
            if y[k, j].data[0] in self.to_predict_code:
                valid_x[k] = 0

        correct_trials = (y_pred == y[:, j]).type(torch.FloatTensor)
        correct = sum((valid_x * correct_trials).data)
        total = sum(valid_x.data)
        loss = torch.mean(valid_x * self.criterion(a, y[:, j]))

        return loss, correct, total

    """ Data Generation """

    def get_data(self):
        """
        Generates training and testing data for this task.
        Inputs consist of strings randomly sampled from
        self.grammar. At each position, the neural network must
        predict the next symbol of the input string.

        :return: None
        """
        self.train_x, self.train_y = self.get_tensors(800)
        self.test_x, self.test_y = self.get_tensors(100)

    def generate_sample_strings(self, remove_duplicates=True):
        """
        Generates all strings from self.grammar up to the
        depth specified by self.depth.

        :type remove_duplicates: bool
        :param remove_duplicates: If True, duplicates will be
            removed.

        :rtype: list
        :return: A list of strings generated by self.grammar
        """
        generator = generate(self.grammar, depth=self.sample_depth)
        if remove_duplicates:
            return [list(y) for y in set(tuple(x) for x in generator)]
        else:
            return list(generator)

    def get_tensors(self, num_tensors):
        """
        Generates a dataset for the word prediction task. The inputs
        consist of sentences uniformly sampled from the grammar. For
        each input, the neural network must predict the next word. Input
        words are represented in one-hot encoding, while output words are
        represented according to self.code_for.

        :type num_tensors: int
        :param num_tensors: The number of sentences to include in
            the tensor

        :rtype: tuple
        :return: Variables containing the input and output data
        """
        x_raw = [self.get_random_sample_string() for _ in xrange(num_tensors)]
        y_raw = [s[1:] for s in x_raw]

        # Initialize x to all nulls
        x = torch.FloatTensor(num_tensors, self.max_length, len(self.code_for))
        x[:, :, :-1].fill_(0)
        x[:, :, -1].fill_(1)

        # Fill in x values
        for i, words in enumerate(x_raw):
            words_one_hot = self.words_to_one_hot(*words)
            for j, word in enumerate(words_one_hot[:self.max_length]):
                x[i, j, :] = word

        # Initialize y to all nulls
        y = torch.LongTensor(num_tensors, self.max_length)
        y[:, :].fill_(self.code_for[self.null])

        # Fill in y values
        for i, words in enumerate(y_raw):
            words_code = self.words_to_code(*words)
            for j, word in enumerate(words_code[:self.max_length]):
                y[i, j] = word

        return Variable(x), Variable(y)

    def get_random_sample_string(self):
        """
        Randomly chooses a string from self.sample_strings with a
        uniform distribution.

        :rtype: list
        :return: A string from self.sample_strings
        """
        return random.choice(self.sample_strings)

    def words_to_code(self, *words):
        """
        Converts one or more words words (terminal s)
        to one-hot representation.

        :type words: unicode
        :param words: One or more words (terminals)

        :rtype: torch.FloatTensor
        :return: The one-hot encoding of the word
        """
        return [self.code_for[word] for word in words]

    def words_to_one_hot(self, *words):
        """
        Converts one or more words (terminal symbols)
        to one-hot representation.

        :type words: unicode
        :param words: One or more words (terminals)

        :rtype: torch.FloatTensor
        :return: The one-hot encoding of the word
        """
        size = len(self.code_for)
        codes = [self.code_for[x] for x in words]

        return [CFGTask.one_hot(x, size) for x in codes]

    @staticmethod
    def one_hot(number, size):
        """
        Computes the following one-hot encoding:
            0 -> [1., 0., 0., ..., 0.]
            1 -> [0., 1., 0., ..., 0.]
            2 -> [0., 0., 1., ..., 0.]
        etc.

        :type number: int
        :param number: A number

        :type size: int
        :param size: The largest possible number plus one

        :rtype: torch.FloatTensor
        :return: The one-hot encoding of the number
        """
        return torch.FloatTensor([float(i == number) for i in xrange(size)])
